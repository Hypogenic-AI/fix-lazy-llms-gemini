\subsection{The Synergy of Motivation and Mechanism}
Our most significant finding is the interaction between subjective persona and objective constraints. The failure of the ``Reasoning Budget'' in isolation (82\% accuracy) challenges the notion that simply scaling test-time compute (via length) automatically yields better reasoning. Without a qualitative directive, the model fills the budget with fluff or ``verbose hallucinations.'' Conversely, the failure of the ``Harsh Critic'' in isolation (80\% accuracy) shows that pressure without a mechanism for improvement is counter-productive. The \textbf{Combined} strategy succeeds because it provides both the \textit{why} (Critic: ``don't be lazy'') and the \textit{how} (Budget: ``take 5 steps'').

\subsection{Does Rudeness Help?}
We explicitly tested the ``Rudeness Hypothesis''---that a hostile environment forces the model to be more careful. Our results suggest a more nuanced reality. While the adversarial ``Harsh Critic'' outperformed the ``Polite'' persona on TruthfulQA, it was surpassed by the ``Skeptical Scientist.'' This indicates that the active ingredient for truthfulness is \textit{skepticism}, not hostility. Rudeness appears to impose a cognitive load that interferes with complex logic (hence the -6\% drop on GSM8K), whereas scientific skepticism provides the necessary rigor without the distraction.

\subsection{Limitations}
Our study has two primary limitations. First, the sample size (n=50) for each condition, while sufficient to show trends, limits the statistical power of our findings (p=0.76 for GSM8K). Larger scale experiments are needed to confirm these effect sizes. Second, we relied on a single model family (`gpt-4o-mini`). It remains to be seen if larger, more capable models (e.g., GPT-4o, Claude 3.5 Sonnet) exhibit the same degree of ``laziness'' or response to these interventions.
